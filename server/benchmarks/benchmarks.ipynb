{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark the new `DoiRegressionModel` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import path\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path.append(f\"{cwd}/..\")\n",
    "\n",
    "from doi_benchmark import Benchmark\n",
    "\n",
    "\n",
    "def benchmark_max_depth(tested_max_depths: range = range(1, 10)):\n",
    "  '''Measures how varying `max_depth` parameter influences progressive DOI prediction scores, over \n",
    "  a series of chunks (without retraining) --- how stable/overfitted is the tree model.'''\n",
    "  benchmark = Benchmark(max_depths=tested_max_depths)\n",
    "  scores = benchmark.run()\n",
    "  return scores\n",
    "\n",
    "\n",
    "def benchmark_retraining_intervals(tested_intervals: range = range(25)):\n",
    "  '''Measures how varying the update interval influences progressive DOI prediction scores.'''\n",
    "  benchmark = Benchmark(intervals=tested_intervals)\n",
    "  scores = benchmark.run()\n",
    "  return scores\n",
    "\n",
    "\n",
    "def benchmark_chunk_size(tested_sizes: range = range(1000, 110000, 10000)):\n",
    "  '''Measures how varying the chunk size influences the progressive DOI prediction scores (without\n",
    "   retraining, without context)'''\n",
    "  benchmark = Benchmark(chunk_size=tested_sizes)\n",
    "  scores = benchmark.run()\n",
    "  return scores\n",
    "\n",
    "\n",
    "def benchmark_context_size(tested_sizes: range = range(0, 11000, 1000)):\n",
    "  '''Measures how varying the context size influences the progressive DOI prediction scores (without\n",
    "   retraining)'''\n",
    "  benchmark = Benchmark(context_size=tested_sizes)\n",
    "  scores = benchmark.run()\n",
    "  return scores\n",
    "\n",
    "\n",
    "def benchmark_context_strategies(context_strats=[\"stratified\", \"minmax\"]):\n",
    "  benchmark = Benchmark(n_chunks=50, context_size=500, intervals=50, measure_doi_error=True, context_strats=context_strats)\n",
    "  scores = benchmark.run()\n",
    "\n",
    "  return scores\n",
    "\n",
    "\n",
    "def benchmark_doi_error_without_context():\n",
    "  '''Measures the changes in DOI error throughout the progression, when no optimizations are \n",
    "   applied.'''\n",
    "  benchmark = Benchmark(n_chunks=100, chunk_size=1000, measure_doi_error=True)\n",
    "  scores = benchmark.run()\n",
    "\n",
    "  return scores\n",
    "\n",
    "  \n",
    "def benchmark_doi_error_with_context():\n",
    "  '''Measures the changes in DOI error throughout the progression, when context optimizations are \n",
    "   applied.'''\n",
    "  benchmark = Benchmark(n_chunks=100, chunk_size=1000, measure_doi_error=True, context_size=1000, intervals=5, context_strats=\"stratified\")\n",
    "  scores = benchmark.run()\n",
    "\n",
    "  return scores\n",
    "\n",
    "def benchmark_retraining_strategies():\n",
    "  '''Measures the changes in DOI error throughout the progression, when context is applied by simply predicting the DOI'''\n",
    "\n",
    "  benchmark = Benchmark(n_chunks=10, chunk_size=1000, context_size=1000, intervals=5, measure_doi_error=True, measure_timings=True, include_previous_chunks_in_training=[True, False])\n",
    "  scores = benchmark.run()\n",
    "\n",
    "  return scores, benchmark\n",
    "\n",
    "def benchmark_with_without_model():\n",
    "  '''Measures the impact of using vs. not using the regression tree model for computing the user interest.'''\n",
    "  benchmark = Benchmark(measure_doi_error=True)\n",
    "\n",
    "  scores = benchmark.run()\n",
    "  return scores, benchmark\n",
    "\n",
    "# TODO: show reduction in overall error when updating \"outdated\" values with each new model\n",
    "\n",
    "# results: max_depth = 3 has best peformance, then no improvement/worse for bigger values\n",
    "# max_depth_results = benchmark_max_depth()\n",
    "\n",
    "# results: trivial best results for 0 and 1, score std for 3-8 above 0.9 \n",
    "# intervals_results = benchmark_retraining_intervals()\n",
    "\n",
    "# results: the larger the context the worse the scores.\n",
    "# context_size_results = benchmark_context_size()\n",
    "\n",
    "# results: the larger the chunk size, the better the scores\n",
    "# chunk_size_results = benchmark_chunk_size()\n",
    "\n",
    "# results: minmax worse than stratified sampling\n",
    "# context_strategies_results = benchmark_context_strategies()\n",
    "\n",
    "# results: overall error increases with every chunk -> DOI values \"age\"\n",
    "# doi_error_without_context_results = benchmark_doi_error_without_context()\n",
    "\n",
    "# results: error increases over time but not as badly as without the context and it gets better\n",
    "# doi_error_with_context_results = benchmark_doi_error_with_context()\n",
    "\n",
    "# results: including the prior model in the update \n",
    "# doi_error_with_prediction_context = benchmark_retraining_strategies()\n",
    "\n",
    "with_without_model = benchmark_with_without_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: Monolithic DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monolithic DOI computation: 376.97526597976685s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import path\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path.append(f\"{cwd}/..\")\n",
    "\n",
    "from doi_benchmark import *\n",
    "\n",
    "N = 1000000\n",
    "storage_monolithic = WindowingStorage(max_size=N * 10)\n",
    "\n",
    "reset(intervals=INTERVALS, weights=WEIGHTS)\n",
    "before = time()\n",
    "chunk_df, chunk_doi = get_next_progressive_result(storage_monolithic, chunk_size=N, chunk_no=0)\n",
    "print(f\"monolithic DOI computation: {time() - before}s\")\n",
    "\n",
    "ids = storage_monolithic.get_available_ids().tolist()\n",
    "\n",
    "slice = N // 10\n",
    "dois_monolithic = pd.DataFrame([], columns=[\"id\", \"doi\"])\n",
    "\n",
    "# duckdb query fails for 1M items in get_all_dois(), so get them in chunks ;)\n",
    "for i in range(10):\n",
    "  id_slice = ids[i*slice : (i+1)*slice]\n",
    "  dois = storage_monolithic.get_doi_for_ids(id_slice).astype(float)\n",
    "  df = pd.DataFrame()\n",
    "  df[\"id\"] = id_slice\n",
    "  df[\"doi\"] = dois\n",
    "  dois_monolithic = pd.concat([dois_monolithic, df], ignore_index=True)\n",
    "\n",
    "dois_monolithic.to_csv(\"monolithic.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: Progressive DOI without our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk-based DOI computation: 144.4384412765503s\n",
      "median time per chunk: 1.428189754486084s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "from sys import path\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path.append(f\"{cwd}/..\")\n",
    "\n",
    "from doi_benchmark import *\n",
    "\n",
    "\n",
    "N = 1000000\n",
    "CHUNK_SIZE = 2000\n",
    "CONTEXT_SIZE = 0\n",
    "N_CHUNKS = 100\n",
    "\n",
    "storage_chunked = WindowingStorage(max_size=N)\n",
    "\n",
    "reset(intervals=INTERVALS, weights=WEIGHTS)\n",
    "timings = []\n",
    "\n",
    "before_all = time()\n",
    "for i in range(N_CHUNKS):\n",
    "  before_chunk = time()\n",
    "  chunk_df, new_dois = get_next_progressive_result(\n",
    "      storage_chunked,\n",
    "      chunk_size=CHUNK_SIZE,\n",
    "      chunk_no=i,\n",
    "  )\n",
    "  timings += [time() - before_chunk]\n",
    "\n",
    "print(f\"chunk-based DOI computation: {time() - before_all}s\")\n",
    "print(f\"median time per chunk: {np.median(timings)}s\")\n",
    "\n",
    "ids = storage_chunked.get_available_ids().tolist()\n",
    "\n",
    "slice = (CHUNK_SIZE * N_CHUNKS) // 10\n",
    "dois_chunked = pd.DataFrame([], columns=[\"id\", \"doi\"])\n",
    "\n",
    "# duckdb query fails for 1M items in get_all_dois(), so get them in chunks ;)\n",
    "for i in range(10):\n",
    "  id_slice = ids[i*slice : (i+1)*slice]\n",
    "  dois = storage_chunked.get_doi_for_ids(id_slice).astype(float)\n",
    "  df = pd.DataFrame()\n",
    "  df[\"id\"] = id_slice\n",
    "  df[\"doi\"] = dois\n",
    "  dois_chunked = pd.concat([dois_chunked, df], ignore_index=True)\n",
    "\n",
    "dois_chunked.to_csv(\"chunked.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Progressive DOI with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk-based DOI computation: 164.3085799217224s\n",
      "median time per chunk: 1.588407278060913s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "from sys import path\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path.append(f\"{cwd}/..\")\n",
    "\n",
    "from doi_benchmark import *\n",
    "\n",
    "\n",
    "N = 1000000\n",
    "CHUNK_SIZE = 1000\n",
    "CONTEXT_SIZE = 1000\n",
    "N_CHUNKS = 100\n",
    "\n",
    "storage_model = WindowingStorage(max_size=N)\n",
    "\n",
    "model = DoiRegressionModel(\n",
    "    storage_model,\n",
    "    max_depth=4,\n",
    "    include_previous_chunks_in_training=False\n",
    ")\n",
    "\n",
    "reset(intervals=INTERVALS, weights=WEIGHTS)\n",
    "timings = []\n",
    "\n",
    "before_all = time()\n",
    "for i in range(100):\n",
    "  before_chunk = time()\n",
    "  # if no model exists, provide no context...\n",
    "  if i == 0:\n",
    "      chunk_df, new_dois = get_next_progressive_result(\n",
    "          storage_model,\n",
    "          chunk_size=CHUNK_SIZE,\n",
    "          chunk_no=i,\n",
    "      )\n",
    "      model.update(chunk_df, new_dois)\n",
    "  # ... otherwise use model to provide context\n",
    "  else:\n",
    "      chunk_df, new_dois = get_next_progressive_result(\n",
    "          storage_model,\n",
    "          chunk_size=CHUNK_SIZE,\n",
    "          chunk_no=i,\n",
    "          get_context=lambda: model.get_context_items(CONTEXT_SIZE),\n",
    "      )\n",
    "  model.update(chunk_df, new_dois, update_outdated=True)\n",
    "  timings += [time() - before_chunk]\n",
    "\n",
    "print(f\"chunk-based DOI computation: {time() - before_all}s\")\n",
    "print(f\"median time per chunk: {np.median(timings)}s\")\n",
    "\n",
    "\n",
    "ids = storage_model.get_available_ids().tolist()\n",
    "\n",
    "slice = (CHUNK_SIZE * N_CHUNKS) // 10\n",
    "dois_model = pd.DataFrame([], columns=[\"id\", \"doi\"])\n",
    "\n",
    "# duckdb query fails for 1M items in get_all_dois(), so get them in chunks ;)\n",
    "for i in range(10):\n",
    "  id_slice = ids[i*slice : (i+1)*slice]\n",
    "  dois = storage_model.get_doi_for_ids(id_slice).astype(float)\n",
    "  df = pd.DataFrame()\n",
    "  df[\"id\"] = id_slice\n",
    "  df[\"doi\"] = dois\n",
    "  dois_model = pd.concat([dois_model, df], ignore_index=True)\n",
    "\n",
    "dois_model.to_csv(\"model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare visualization with and without our model when progressively analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "s = with_without_model[1].storages[0]\n",
    "\n",
    "nrow = 1\n",
    "ncol = 3\n",
    "plot_size = 4\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(ncol * plot_size, plot_size), sharex=True, sharey=True)\n",
    "\n",
    "for i in range(ncol):\n",
    "  # chunk_df = s.get_items_for_chunks(chunks=list(range(i + 1)), as_df=True)\n",
    "  chunk_df = s.get_items_for_chunks(chunks=[i], as_df=True)\n",
    "  doi = s.get_doi_for_ids(chunk_df[\"tripID\"].tolist())\n",
    "  chunk_df[\"doi\"] = doi.astype(float)\n",
    "  \n",
    "  chunk_df.plot.scatter(\n",
    "    x=\"trip_distance\", \n",
    "    y=\"total_amount\", \n",
    "    alpha=chunk_df[\"doi\"], \n",
    "    c=chunk_df[\"doi\"], \n",
    "    ax=axes[i], \n",
    "    cmap=\"viridis\"\n",
    "  )\n",
    "  axes[i].set_xticks([])\n",
    "  axes[i].set_yticks([])\n",
    "\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(axes[0], cax=cbar_ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "doi_error_with_prediction_context[~doi_error_with_prediction_context[\"include_previous_chunks_in_training\"]].plot(x=\"chunk\", y=\"error_mean\", ax=axes[0])\n",
    "doi_error_with_prediction_context[doi_error_with_prediction_context[\"include_previous_chunks_in_training\"]].plot(x=\"chunk\", y=\"error_mean\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5), sharey=True)\n",
    "\n",
    "doi_error_with_prediction_context.boxplot(column=\"score\", by=\"include_previous_chunks_in_training\", ax=axes[0])\n",
    "\n",
    "doi_error_with_prediction_context[~doi_error_with_prediction_context[\"include_previous_chunks_in_training\"]].plot(y=\"score\", x=\"chunk\", ax=axes[1])\n",
    "\n",
    "doi_error_with_prediction_context[doi_error_with_prediction_context[\"include_previous_chunks_in_training\"]].plot(y=\"score\", x=\"chunk\", ax=axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True, sharex=True)\n",
    "\n",
    "doi_error_without_context_results[\"error_std\"].plot(ax=axes[0])\n",
    "doi_error_with_context_results[\"error_std\"].plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "context_strategies_results.boxplot(column=\"error_std\", by=\"context_strat\", ax=axes[0])\n",
    "context_strategies_results.plot(y=\"error_std\", x=\"chunk\",  ax=axes[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_results.boxplot(column=\"score\", by=\"max_depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_results.boxplot(column=\"score\", by=\"interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size_results.boxplot(column=\"score\", by=\"context_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size_results.boxplot(column=\"score\", by=\"chunk_size\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a8a56818e4b25fbd98bc0023c60094171877367c6f31cf9f5d664356b3a0116"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
