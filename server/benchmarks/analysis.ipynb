{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI histogram ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from notebook_test_case import *\n",
    "from analysis import *\n",
    "\n",
    "ground_truth_df = pd.read_csv(f\"{PATH}/doi/__ground_truth__.csv\")\n",
    "ground_truth_bins = get_doi_bins_df(ground_truth_df, PARAMETERS.n_bins)\n",
    "ground_truth_bins.columns = [\"count\"]\n",
    "ground_truth_bins[\"bin\"] = ground_truth_bins.index\n",
    "\n",
    "alt.Chart(ground_truth_bins).mark_bar().encode(\n",
    "  x=alt.X(\"bin:N\"),\n",
    "  y=alt.Y(\"count:Q\"),\n",
    "  tooltip=\"count:Q\",\n",
    ").properties(\n",
    "  width=400,\n",
    "  height=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of the dataset under analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from notebook_test_case import *\n",
    "\n",
    "df = pd.read_csv(DATA.data_path)\n",
    "doi = pd.read_csv(f\"{PATH}/doi/__ground_truth__.csv\")\n",
    "df_ = df.copy()\n",
    "df_[\"doi\"] = 0\n",
    "sample = df_[:10000]\n",
    "\n",
    "print(df.shape, doi.shape)\n",
    "\n",
    "points = alt.Chart(sample).mark_circle().encode(\n",
    "  x=alt.X(field=DATA.numeric_columns[0], type=\"quantitative\"),\n",
    "  y=alt.Y(field=DATA.numeric_columns[-1], type=\"quantitative\"),\n",
    "  # color=alt.Color(\"doi:Q\")\n",
    "  opacity={\"value\": 0.1}\n",
    ")\n",
    "grid = alt.Chart(sample).mark_bar().encode(\n",
    "  x=alt.X(field=DATA.numeric_columns[0], type=\"quantitative\", bin=True),\n",
    "  y=alt.Y(field=DATA.numeric_columns[-1], type=\"quantitative\", bin=True),\n",
    "  color=alt.Color(\"count():Q\", scale=alt.Scale(scheme=\"blues\"))\n",
    ")\n",
    "grid + points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger chunks vs. ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from notebook_test_case import *\n",
    "\n",
    "\n",
    "ground_truth_df = pd.read_csv(f\"{PATH}/doi/__ground_truth__.csv\")\n",
    "ground_truth_bins = get_doi_bins_df(ground_truth_df, PARAMETERS.n_bins, with_labels=True)\n",
    "\n",
    "bigger_chunks_df = pd.read_csv(f\"{PATH}/doi/__bigger_chunks__.csv\")\n",
    "bigger_chunks_bins = get_doi_bins_df(bigger_chunks_df, PARAMETERS.n_bins, with_labels=True)\n",
    "\n",
    "delta_bins_df = get_doi_delta_bins_df(bigger_chunks_bins[0], ground_truth_bins[0], PARAMETERS.total_size, \n",
    "                                      PARAMETERS.n_bins)\n",
    "\n",
    "alt.Chart(delta_bins_df).mark_bar(size=5).encode(\n",
    "  x=alt.X(\"bin:Q\"),\n",
    "  y=alt.Y(\"delta:Q\"),\n",
    "  tooltip=alt.Tooltip([\"bin\", \"delta\"]),\n",
    ").properties(\n",
    "  width=100,\n",
    "  height=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy-based Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI distributions per use case in histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import altair as alt\n",
    "from notebook_test_case import PATH, PARAMETERS, CONTEXT_STRATEGIES, UPDATE_STRATEGIES\n",
    "from analysis import *\n",
    "\n",
    "charts = []\n",
    "\n",
    "# load all data from the out directory into one dataframe and add a column that indicates the context\n",
    "# and update strategies used in this particular use case\n",
    "available_test_cases = os.listdir(f\"{PATH}/doi\")\n",
    "\n",
    "# compute the ground truth bins \n",
    "ground_truth_df = pd.read_csv(f\"{PATH}/doi/__ground_truth__.csv\")\n",
    "ground_truth_bins = get_doi_bins_df(ground_truth_df, PARAMETERS.n_bins)\n",
    "\n",
    "all_doi_bins_df = pd.DataFrame()\n",
    "\n",
    "# compute the bins for each combination of strategies and then compare it to the ground truth in a \n",
    "# layered histogram\n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    # bin the doi data \n",
    "    df = pd.read_csv(f\"{PATH}/doi/{test_case}\")\n",
    "    df_bins = get_doi_bins_df(df, PARAMETERS.n_bins)\n",
    "\n",
    "    df_bins.columns = [\"count\"]\n",
    "    df_bins[\"bin\"] = df_bins.index\n",
    "    df_bins[\"context_strategy\"] = c_strat[0]\n",
    "    df_bins[\"update_strategy\"] = u_strat[0]\n",
    "\n",
    "    all_doi_bins_df = all_doi_bins_df.append(df_bins)\n",
    "\n",
    "all_doi_bins_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(all_doi_bins_df)\n",
    "\n",
    "alt.Chart(all_doi_bins_df).mark_bar().encode(\n",
    "  x=alt.X(\"bin:N\"),\n",
    "  y=alt.Y(\"count:Q\"),\n",
    "  tooltip=alt.Tooltip([\"bin\", \"count\"]),\n",
    ").properties(\n",
    "  width=100,\n",
    "  height=100\n",
    ").facet(\n",
    "  row=\"context_strategy\",\n",
    "  column=\"update_strategy\",\n",
    "  spacing=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in DOI distributions per use case in histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import altair as alt\n",
    "from notebook_test_case import PATH, PARAMETERS, CONTEXT_STRATEGIES, UPDATE_STRATEGIES\n",
    "from analysis import *\n",
    "\n",
    "charts = []\n",
    "\n",
    "# load all data from the out directory into one dataframe and add a column that indicates the context\n",
    "# and update strategies used in this particular use case\n",
    "available_test_cases = os.listdir(f\"{PATH}/doi\")\n",
    "\n",
    "# compute the ground truth bins \n",
    "ground_truth_df = pd.read_csv(f\"{PATH}/doi/__ground_truth__.csv\")\n",
    "ground_truth_bins = get_doi_bins_df(ground_truth_df, PARAMETERS.n_bins)\n",
    "\n",
    "all_doi_bins_df = pd.DataFrame()\n",
    "\n",
    "# compute the bins for each combination of strategies and then compare it to the ground truth in a \n",
    "# layered histogram\n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    # bin the doi data \n",
    "    df = pd.read_csv(f\"{PATH}/doi/{test_case}\")\n",
    "    bins_df = get_doi_bins_df(df, PARAMETERS.n_bins)\n",
    "\n",
    "    doi_delta_bins = get_doi_delta_bins_df(bins_df, ground_truth_bins)\n",
    "\n",
    "    doi_delta_bins[\"context_strategy\"] = c_strat[0]\n",
    "    doi_delta_bins[\"update_strategy\"] = u_strat[0]\n",
    "\n",
    "    all_doi_bins_df = all_doi_bins_df.append(doi_delta_bins)\n",
    "\n",
    "max_count = ground_truth_bins.max()[0]\n",
    "\n",
    "alt.Chart(all_doi_bins_df).mark_bar().encode(\n",
    "  x=alt.X(\"bin:Q\"),\n",
    "  y=alt.Y(\"delta:Q\", scale=alt.Scale(domain=[-max_count, max_count])),\n",
    "  tooltip=alt.Tooltip([\"bin\", \"delta\"]),\n",
    ").properties(\n",
    "  width=100,\n",
    "  height=100\n",
    ").facet(\n",
    "  row=\"context_strategy\",\n",
    "  column=\"update_strategy\",\n",
    "  spacing=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin-based accuracy per item per test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_test_case import *\n",
    "from analysis import *\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from database import ID, DOI\n",
    "from test_case import get_full_title\n",
    "\n",
    "\n",
    "id = ID.lower()\n",
    "doi = DOI.lower()\n",
    "gt = pd.read_csv(f\"{PATH}/doi/__ground_truth__.csv\")\n",
    "gt_bin_labels = get_doi_bins_df(gt, PARAMETERS.n_bins, with_labels=True)[1]\n",
    "\n",
    "available_test_cases = os.listdir(f\"{PATH}/doi\")\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# compute the overlap between the two \n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    # read the benchmark results\n",
    "    df = pd.read_csv(f\"{PATH}/doi/{test_case}\")\n",
    "    bin_labels = get_doi_bins_df(df, PARAMETERS.n_bins, True)[1]\n",
    "    diff = get_doi_bin_error_df(gt_bin_labels, bin_labels)\n",
    "    diff[\"context_strategy\"] = c_strat[0]\n",
    "    diff[\"update_strategy\"] = u_strat[0]\n",
    "    \n",
    "    results = results.append(diff)\n",
    "\n",
    "strategies_chart = alt.Chart(results).mark_bar().encode(\n",
    "  x=\"count:Q\",\n",
    "  y=alt.Y(\"update_strategy:N\", title=None),\n",
    "  row=\"context_strategy:N\",\n",
    "  stroke={\"value\": \"#fff\"},\n",
    "  color=alt.Color(\"diff:Q\", scale=alt.Scale(scheme='viridis')),\n",
    "  tooltip=[\"diff\", \"count\"],\n",
    ")\n",
    "\n",
    "bigger_chunks_df = pd.read_csv(f\"{PATH}/doi/__bigger_chunks__.csv\")\n",
    "bigger_chunks_bins = get_doi_bins_df(bigger_chunks_df, PARAMETERS.n_bins, with_labels=True)\n",
    "\n",
    "doi_bin_error_df = get_doi_bin_error_df(bigger_chunks_bins[1], gt_bin_labels)\n",
    "\n",
    "bigger_chunks_chart = alt.Chart(doi_bin_error_df).mark_bar().encode(\n",
    "  x=\"count:Q\",\n",
    "  stroke={\"value\": \"#fff\"},\n",
    "  color=alt.Color(\"diff:Q\", scale=alt.Scale(scheme='viridis')),\n",
    "  tooltip=[\"diff\", \"count\"],\n",
    ").properties(\n",
    "  title=\"Bigger chunks:\"\n",
    ")\n",
    "\n",
    "print(\"doi accuracy per item:\")\n",
    "alt.vconcat(strategies_chart, bigger_chunks_chart).properties(\n",
    "  title=get_full_title(DOI_CONFIG, PARAMETERS, DATA),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error per item per strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from notebook_test_case import *\n",
    "from test_case import get_full_title\n",
    "from analysis import *\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "gt = pd.read_csv(f\"{PATH}/doi/__ground_truth__.csv\")\n",
    "\n",
    "available_test_cases = os.listdir(f\"{PATH}/doi\")\n",
    "strategies_error = pd.DataFrame()\n",
    "\n",
    "# compute the overlap between the two \n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    # read the benchmark results\n",
    "    df = pd.read_csv(f\"{PATH}/doi/{test_case}\")\n",
    "    strategy_error = get_doi_error_df(gt, df, absolute=False)\n",
    "\n",
    "    strategy_error[\"context_strategy\"] = c_strat[0]\n",
    "    strategy_error[\"update_strategy\"] = u_strat[0]\n",
    "    strategies_error = strategies_error.append(strategy_error)\n",
    "\n",
    "bigger_chunks_df = pd.read_csv(f\"{PATH}/doi/__bigger_chunks__.csv\")\n",
    "bigger_chunks_error = get_doi_error_df(gt, bigger_chunks_df, absolute=False)\n",
    "\n",
    "doi_max = max(strategies_error[\"doi\"].max(), bigger_chunks_error[\"doi\"].max())\n",
    "\n",
    "strategy_chart = alt.Chart(strategies_error).mark_boxplot().encode(\n",
    "  x=alt.X(\"doi:Q\", title=None, scale=alt.Scale(domain=[-doi_max, doi_max])),\n",
    "  y=alt.Y(\"context_strategy:N\", title=None),\n",
    "  opacity=alt.condition(\n",
    "    (alt.datum.context_strategy == \"no context\") |  (alt.datum.update_strategy == \"no update\"), \n",
    "    alt.value(0.3),\n",
    "    alt.value(1)\n",
    "  ),\n",
    "  row=\"update_strategy:N\",\n",
    "  tooltip=\"doi:Q\"\n",
    ")\n",
    "\n",
    "bigger_chunks_chart = alt.Chart(bigger_chunks_error).mark_boxplot().encode(\n",
    "  x=alt.X(\"doi:Q\", title=None, scale=alt.Scale(domain=[-doi_max, doi_max])),\n",
    "  tooltip=\"doi:Q\"\n",
    ").properties(\n",
    "  title=\"using bigger chunks:\"\n",
    ")\n",
    "\n",
    "alt.vconcat(strategy_chart, bigger_chunks_chart).properties(\n",
    "  title=get_full_title(DOI_CONFIG, PARAMETERS, DATA),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error difference sequential vs. mixed-in context computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_test_case import *\n",
    "from analysis import *\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "available_test_cases = os.listdir(f\"{PATH}/doi\")\n",
    "strategies_diff = pd.DataFrame()\n",
    "\n",
    "# compute the overlap between the two \n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    # read the benchmark results\n",
    "    df_mixed = pd.read_csv(f\"{PATH}/doi/{test_case}\")\n",
    "    df_sequential = pd.read_csv(f\"{PATH}/doi-seq/{test_case}\")\n",
    "    \n",
    "    strategy_diff = get_doi_error_df(df_sequential, df_mixed, absolute=False)\n",
    "    strategy_diff[\"context_strategy\"] = c_strat[0]\n",
    "    strategy_diff[\"update_strategy\"] = u_strat[0]\n",
    "    \n",
    "    strategies_diff = strategies_diff.append(strategy_diff)\n",
    "\n",
    "grouped = strategies_diff.groupby([\"context_strategy\", \"update_strategy\"]).mean()\n",
    "grouped = pd.DataFrame(grouped).reset_index()\n",
    "\n",
    "alt.Chart(grouped).mark_bar().encode(\n",
    "  x=alt.X(\"context_strategy:N\", title=None),\n",
    "  y=alt.Y(\"doi:Q\", title=None, scale=alt.Scale(domain=[-0.25, 0.25])),\n",
    "  opacity=alt.condition(\n",
    "    (alt.datum.context_strategy == \"no context\") |  (alt.datum.update_strategy == \"no update\"), \n",
    "    alt.value(0.3),\n",
    "    alt.value(1)\n",
    "  ),\n",
    "  color=alt.condition(\n",
    "    alt.datum.value > 0,\n",
    "    alt.value(\"firebrick\"),\n",
    "    alt.value(\"GREEN\"),\n",
    "  ),\n",
    "  column=alt.Column(\"update_strategy:N\"),\n",
    "  tooltip=\"doi:Q\"\n",
    ").properties(\n",
    "  height=100,\n",
    "  width=175,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total time per test case in boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from notebook_test_case import *\n",
    "\n",
    "charts = []\n",
    "\n",
    "# load all data from the out directory into one dataframe and add a column that indicates the context\n",
    "# and update strategies used in this particular use case\n",
    "available_test_cases = os.listdir(f\"{PATH}/times\")\n",
    "available_test_cases\n",
    "\n",
    "all_doi_values_df = pd.DataFrame()\n",
    "\n",
    "# build one big dataframe containing all doi scores and label each based on the strategies that were\n",
    "# used to generate them\n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    df = pd.read_csv(f\"{PATH}/times/{test_case}\")\n",
    "    df[\"context_strategy\"] = c_strat[0]\n",
    "    df[\"update_strategy\"] = u_strat[0]\n",
    "    all_doi_values_df = all_doi_values_df.append(df)\n",
    "    all_doi_values_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "chart1 = alt.Chart(all_doi_values_df).mark_boxplot().encode(\n",
    "  x=\"update_strategy:N\",\n",
    "  y={\"field\": \"total_time\", \"type\": \"quantitative\", \"scale\": {\"type\": \"linear\"}, \"title\": \"time (s)\"},\n",
    "  column=\"context_strategy:N\",\n",
    "  color=alt.value(\"#BEAED4\")\n",
    ").properties(\n",
    "  width=120,\n",
    "  height=250\n",
    ")\n",
    "\n",
    "chart2 = alt.Chart(all_doi_values_df).mark_boxplot().encode(\n",
    "  x=\"context_strategy:N\",\n",
    "  y={\"field\": \"total_time\", \"type\": \"quantitative\", \"scale\": {\"type\": \"linear\"}, \"title\": \"time (s)\"},\n",
    "  column=\"update_strategy:N\",\n",
    "  color=alt.value(\"#FDC086\")\n",
    ").properties(\n",
    "  width=120,\n",
    "  height=250,\n",
    ")\n",
    "\n",
    "alt.vconcat(chart1, chart2).properties(\n",
    "  title=get_full_title(DOI_CONFIG, PARAMETERS, DATA),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated total time per strategy in boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "charts = []\n",
    "\n",
    "# load all data from the out directory into one dataframe and add a column that indicates the context\n",
    "# and update strategies used in this particular use case\n",
    "available_test_cases = os.listdir(f\"{PATH}/times\")\n",
    "available_test_cases\n",
    "\n",
    "all_time_series_df = pd.DataFrame()\n",
    "\n",
    "# build one big dataframe containing all doi scores and label each based on the strategies that were\n",
    "# used to generate them\n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    df = pd.read_csv(f\"{PATH}/times/{test_case}\")\n",
    "    df[\"context_strategy\"] = c_strat[0]\n",
    "    df[\"update_strategy\"] = u_strat[0]\n",
    "    all_time_series_df = all_time_series_df.append(df)\n",
    "    all_time_series_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "chart1 = alt.Chart(all_time_series_df).mark_boxplot().encode(\n",
    "  x=\"context_strategy:N\",\n",
    "  y=alt.Y(\"total_time:Q\", title=\"time (s)\"),\n",
    "  color=alt.value(\"#BEAED4\")\n",
    ").properties(\n",
    "  width=320,\n",
    "  height=150\n",
    ")\n",
    "\n",
    "chart2 = alt.Chart(all_time_series_df).mark_boxplot().encode(\n",
    "  x=\"update_strategy:N\",\n",
    "  y=alt.Y(\"total_time:Q\", title=\"time (s)\"),\n",
    "  color=alt.value(\"#FDC086\")\n",
    ").properties(\n",
    "  width=320,\n",
    "  height=150\n",
    ")\n",
    "\n",
    "alt.hconcat(chart1, chart2).properties(\n",
    "  title=get_full_title(DOI_CONFIG, PARAMETERS, DATA),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series for each test case step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "all_timeseries_df = pd.DataFrame()\n",
    "\n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    df = pd.read_csv(f\"{PATH}/times/{test_case}\")\n",
    "    df[\"context_strategy\"] = c_strat[0]\n",
    "    df[\"update_strategy\"] = u_strat[0]\n",
    "    all_timeseries_df = all_timeseries_df.append(df)\n",
    "    all_timeseries_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# temporal_columns = [\"chunk_time\", \"context_time\", \"outdated_time\", \"old_doi_time\", \n",
    "#    \"store_new_time\", \"update_dois_time\", \"total_time\"]\n",
    "\n",
    "temporal_columns = [\"chunk_time\", \"context_time\", \"outdated_time\"]\n",
    "\n",
    "alt.Chart(all_timeseries_df).transform_fold(\n",
    "  temporal_columns\n",
    ").mark_line().encode(\n",
    "  x=\"chunk:N\",\n",
    "  y=\"value:Q\",\n",
    "  color=\"key:N\",\n",
    "  column=\"update_strategy:N\",\n",
    "  row=\"context_strategy:N\",\n",
    "  tooltip=\"temporal_columns:Q\"\n",
    ").properties(\n",
    "  height=100,\n",
    "  width=200,\n",
    "  spacing=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated Time series per strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "charts = []\n",
    "\n",
    "# load all data from the out directory into one dataframe and add a column that indicates the context\n",
    "# and update strategies used in this particular use case\n",
    "available_test_cases = os.listdir(f\"{PATH}/times\")\n",
    "available_test_cases\n",
    "\n",
    "all_timeseries_df = pd.DataFrame()\n",
    "\n",
    "# build one big dataframe containing all doi scores and label each based on the strategies that were\n",
    "# used to generate them\n",
    "for c_strat in CONTEXT_STRATEGIES:\n",
    "  for u_strat in UPDATE_STRATEGIES:\n",
    "    # check if that test case exists\n",
    "    test_case = f\"{u_strat[0]}-{c_strat[0]}.csv\"\n",
    "    if test_case not in available_test_cases:\n",
    "      continue\n",
    "\n",
    "    df = pd.read_csv(f\"{PATH}/times/{test_case}\")\n",
    "    df[\"context_strategy\"] = c_strat[0]\n",
    "    df[\"update_strategy\"] = u_strat[0]\n",
    "    all_timeseries_df = all_timeseries_df.append(df)\n",
    "    all_timeseries_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "alt.Chart(all_timeseries_df).mark_line().encode(\n",
    "  x=\"chunk:Q\",\n",
    "  y={\"field\": \"total_time\", \"type\": \"quantitative\", \"scale\": {\"type\": \"linear\"}, \"title\": \"time (s)\"},\n",
    "  row=\"context_strategy:N\",\n",
    "  color=\"update_strategy:N\",\n",
    ").properties(\n",
    "  width=800,\n",
    "  height=120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "out_folder = \"./out/\"\n",
    "test_cases = [f for f in os.listdir(out_folder) if os.path.isfile(join(out_folder, f))]\n",
    "test_cases = [tc for tc in test_cases if \"strategies\" not in tc]\n",
    "\n",
    "if len(test_cases) == 0:\n",
    "  print(\"no test cases were found that are not strategy-based.\")\n",
    "\n",
    "doi_test_case_dropdown = widgets.Dropdown(\n",
    "  description=\"Non-strategy runs\",\n",
    "  options=test_cases,\n",
    "  disabled=len(test_cases) == 0,\n",
    "  style={\"description_width\": \"initial\"},\n",
    ")\n",
    "display(doi_test_case_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error per item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os.path import join\n",
    "from notebook_test_case import PATH, TEST_CASE_INDEX\n",
    "from benchmarks import load_test_case, MODES\n",
    "from test_case import get_full_title\n",
    "from analysis import get_strategy_bc_errors\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "if doi_test_case_dropdown.value is None:\n",
    "  raise Exception(\"select a test case first using the widget above\")\n",
    "\n",
    "selected_test_case = json.load(open(\"./out/\"+doi_test_case_dropdown.value))\n",
    "\n",
    "test_case_doi_paths = [t[\"dois_path\"] for t in selected_test_case[\"test_cases\"]]\n",
    "test_case_preset = load_test_case(selected_test_case[\"preset_index\"])\n",
    "doi_file_name = f\"{test_case_preset.name}.csv\"  # filename consists of the strategies in the preset\n",
    "data_label = test_case_preset.data.name\n",
    "params_label = test_case_preset.params.name\n",
    "\n",
    "mode = selected_test_case[\"mode\"]\n",
    "print(MODES, mode, MODES.index(mode))\n",
    "\n",
    "strategies_error, bigger_chunks_errors = get_strategy_bc_errors(\n",
    "  path_list=test_case_doi_paths,\n",
    "  file_name=doi_file_name,\n",
    "  label=mode,\n",
    "  absolute=False\n",
    ")\n",
    "\n",
    "doi_max = max(strategies_error[\"doi\"].max(), bigger_chunks_errors[\"doi\"].max())\n",
    "\n",
    "strategy_chart = alt.Chart(strategies_error).mark_boxplot().encode(\n",
    "  x=alt.X(\"doi:Q\", title=None, scale=alt.Scale(domain=[-doi_max, doi_max])),\n",
    "  y=alt.Y(f\"{mode}:N\", title=None),\n",
    "  # row=\"update_strategy:N\",\n",
    "  tooltip=\"doi:Q\"\n",
    ").properties(\n",
    "  title=f\"{doi_file_name}\",\n",
    ")\n",
    "\n",
    "bigger_chunks_chart = alt.Chart(bigger_chunks_errors).mark_boxplot().encode(\n",
    "  x=alt.X(\"doi:Q\", title=None, scale=alt.Scale(domain=[-doi_max, doi_max])),\n",
    "  y=alt.Y(f\"{mode}:N\", title=None),\n",
    "  # row=\"update_strategy:N\",\n",
    "  tooltip=\"doi:Q\"\n",
    ").properties(\n",
    "  title=\"using bigger chunks:\"\n",
    ")\n",
    "\n",
    "alt.vconcat(strategy_chart, bigger_chunks_chart).properties(\n",
    "  title=f\"Prediction error for {data_label} at {params_label}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin-based difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import altair as alt\n",
    "from notebook_test_case import PATH, PARAMETERS, CONTEXT_STRATEGIES, UPDATE_STRATEGIES\n",
    "from analysis import *\n",
    "\n",
    "charts = []\n",
    "\n",
    "# load all data from the out directory into one dataframe and add a column that indicates the context\n",
    "# and update strategies used in this particular use case\n",
    "available_test_cases = os.listdir(f\"./out/taxis-shuffled/outlierness/1200000/1000/doi\")\n",
    "\n",
    "# compute the ground truth bins \n",
    "ground_truth_df = pd.read_csv(f\"./out/taxis-shuffled/outlierness/12000/1000/doi/__ground_truth__.csv\")\n",
    "ground_truth_bins = get_doi_bins_df(ground_truth_df, PARAMETERS.n_bins)\n",
    "\n",
    "\n",
    "if doi_test_case_dropdown.value is None:\n",
    "  raise Exception(\"select a test case first using the widget above\")\n",
    "\n",
    "selected_test_case = json.load(open(\"./out/\"+doi_test_case_dropdown.value))\n",
    "\n",
    "test_case_doi_paths = [t[\"dois_path\"] for t in selected_test_case[\"test_cases\"]]\n",
    "test_case_preset = load_test_case(selected_test_case[\"preset_index\"])\n",
    "doi_file_name = f\"{test_case_preset.name}.csv\"  # filename consists of the strategies in the preset\n",
    "data_label = test_case_preset.data.name\n",
    "params_label = test_case_preset.params.name\n",
    "\n",
    "mode = selected_test_case[\"mode\"]\n",
    "for test_case_path in test_case_doi_paths:\n",
    "  # bin the doi data \n",
    "  df = pd.read_csv(f\"{test_case_path}/{doi_file_name}\")\n",
    "  df_bins = get_doi_bins_df(df, PARAMETERS.n_bins)\n",
    "\n",
    "  df_bins.columns = [\"count\"]\n",
    "  df_bins[\"bin\"] = df_bins.index\n",
    "\n",
    "  if mode == \"dois\":\n",
    "    test_case_label = test_case_path.split(\"/\")[3]\n",
    "  elif mode == \"datasets\":\n",
    "    test_case_label = test_case_path.split(\"/\")[2]\n",
    "  elif mode == \"parameters\":\n",
    "    test_case_label = \"\".join(test_case_path.split(\"/\")[-3:-1])  # include data and chunk sizes\n",
    "\n",
    "  df_bins[\"mode\"] = test_case_label\n",
    "\n",
    "  all_doi_bins_df = all_doi_bins_df.append(df_bins)\n",
    "\n",
    "all_doi_bins_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "alt.Chart(all_doi_bins_df).mark_bar().encode(\n",
    "  x=alt.X(\"bin:N\"),\n",
    "  y=alt.Y(\"count:Q\"),\n",
    "  tooltip=alt.Tooltip([\"bin\", \"count\"]),\n",
    ").properties(\n",
    "  width=100,\n",
    "  height=100\n",
    ").facet(\n",
    "  column=\"mode\",\n",
    "  spacing=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Composite Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from ipywidgets import widgets, HBox\n",
    "from IPython.display import display\n",
    "\n",
    "out_folder = \"./out/\"\n",
    "test_cases = [f for f in os.listdir(out_folder) if os.path.isfile(join(out_folder, f))]\n",
    "test_cases = [tc for tc in test_cases if \"composite\" in tc]\n",
    "\n",
    "if len(test_cases) == 0:\n",
    "  print(\"no test cases found.\")\n",
    "\n",
    "composite_test_case_dropdown = widgets.Dropdown(\n",
    "  description=\"test case:\",\n",
    "  options=test_cases,\n",
    "  disabled=len(test_cases) == 0,\n",
    "  style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "mode_dropdown = widgets.Dropdown(\n",
    "  description=\"mode:\",\n",
    "  options=[\"datasets\", \"strategies\", \"dois\", \"parameters\"],\n",
    "  style={\"description_width\": \"40px\"},\n",
    ")\n",
    "\n",
    "column_dropdown = widgets.Dropdown(\n",
    "  description=\"columns:\",\n",
    "  options=[\"context_strategy\", \"update_strategy\", \"storage_strategy\"],\n",
    "  style={\"description_width\": \"60px\"},\n",
    ")\n",
    "row_dropdown = widgets.Dropdown(\n",
    "  description=\"rows\",\n",
    "  options=[\"update_strategy\", \"context_strategy\", \"storage_strategy\"],\n",
    "  style={\"description_width\": \"30px\"},\n",
    ")\n",
    "\n",
    "\n",
    "HBox([composite_test_case_dropdown, mode_dropdown, column_dropdown, row_dropdown])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI distribution for all combinations compared to bigger chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import notebook_test_case  # for fixing the PATH variable\n",
    "from test_case import get_full_title\n",
    "from analysis import get_error_for_test_case, merge_err_dfs\n",
    "\n",
    "if composite_test_case_dropdown.value is None or mode_dropdown.value is None:\n",
    "  raise Exception(\"select a test case and mode with the widget above\")\n",
    "\n",
    "mode = mode_dropdown.value\n",
    "all_strategies_error, all_bc_errors, _ = get_error_for_test_case(\n",
    "  test_case_file_name=composite_test_case_dropdown.value, \n",
    "  mode=mode\n",
    ")\n",
    "df = merge_err_dfs(all_strategies_error, all_bc_errors, mode=mode)\n",
    "\n",
    "column = column_dropdown.value\n",
    "row = row_dropdown.value\n",
    "\n",
    "grid = sns.FacetGrid(\n",
    "  data=df,\n",
    "  row=row,\n",
    "  col=column,\n",
    "  margin_titles=True,\n",
    "  hue=\"type\",\n",
    ")\n",
    "grid.map_dataframe(sns.histplot, x=\"doi\", binwidth=0.1, kde=True)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import notebook_test_case  # for fixing the PATH variable\n",
    "from test_case import get_full_title\n",
    "from analysis import get_error_for_test_case, merge_err_dfs\n",
    "\n",
    "if composite_test_case_dropdown.value is None or mode_dropdown.value is None:\n",
    "  raise Exception(\"select a test case and mode with the widget above\")\n",
    "\n",
    "mode = mode_dropdown.value\n",
    "all_strategies_error, all_bc_errors, all_sc_errors = get_error_for_test_case(\n",
    "  test_case_file_name=composite_test_case_dropdown.value, \n",
    "  mode=mode\n",
    ")\n",
    "df = merge_err_dfs(all_strategies_error, all_sc_errors, mode=mode)\n",
    "\n",
    "column = column_dropdown.value\n",
    "row = row_dropdown.value\n",
    "\n",
    "grid = sns.FacetGrid(\n",
    "  data=df,\n",
    "  row=row,\n",
    "  col=column,\n",
    "  margin_titles=True,\n",
    "   hue=\"type\",\n",
    ")\n",
    "\n",
    "grid.map_dataframe(sns.histplot, x=\"doi\", binwidth=0.1)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error for all combinations in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import notebook_test_case  # for fixing the PATH variable\n",
    "from test_case import get_full_title\n",
    "from analysis import get_error_for_test_case, merge_err_dfs\n",
    "\n",
    "if composite_test_case_dropdown.value is None or mode_dropdown.value is None:\n",
    "  raise Exception(\"select a test case and mode with the widget above\")\n",
    "\n",
    "mode = mode_dropdown.value\n",
    "all_strategies_error, all_bigger_chunks_error, _ = get_error_for_test_case(\n",
    "  test_case_file_name=composite_test_case_dropdown.value, \n",
    "  mode=mode\n",
    ")\n",
    "df = merge_err_dfs(all_strategies_error, all_bigger_chunks_error, mode=mode)\n",
    "\n",
    "column = column_dropdown.value\n",
    "row = row_dropdown.value\n",
    "\n",
    "plot = sns.catplot(\n",
    "  kind=\"box\", \n",
    "  data=df, \n",
    "  x=mode, \n",
    "  y=\"doi\", \n",
    "  row=row,\n",
    "  col=column,\n",
    "  hue=\"type\", \n",
    "  linewidth=1, \n",
    "  margin_titles=True\n",
    ")\n",
    "\n",
    "# Finalize the figure\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error aggregated by strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import notebook_test_case  # for fixing the PATH variable\n",
    "from test_case import get_full_title\n",
    "from analysis import get_error_for_test_case, merge_err_dfs\n",
    "\n",
    "if composite_test_case_dropdown.value is None or mode_dropdown.value is None:\n",
    "  raise Exception(\"select a test case and mode with the widget above\")\n",
    "\n",
    "mode = mode_dropdown.value\n",
    "all_strategies_error, all_bigger_chunks_error, _ = get_error_for_test_case(\n",
    "  test_case_file_name=composite_test_case_dropdown.value, \n",
    "  mode=mode\n",
    ")\n",
    "df = merge_err_dfs(all_strategies_error, all_bigger_chunks_error, mode=mode)\n",
    "\n",
    "column = column_dropdown.value\n",
    "row = row_dropdown.value\n",
    "\n",
    "plot = sns.catplot(\n",
    "  kind=\"box\", \n",
    "  data=df, \n",
    "  x=mode, \n",
    "  y=\"doi\", \n",
    "  hue=\"type\", \n",
    "  palette=\"Set3\", \n",
    "  linewidth=1, \n",
    ")\n",
    "\n",
    "# Finalize the figure\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results aggregated by mode"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
