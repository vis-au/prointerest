{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies for Progressively Storing Processed Data\n",
    "In this notebook, we introduce and benchmark basic algorithms presented in our paper for storing data and their results that are made available in chunks (\"progressively\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import path\n",
    "cwd = os.getcwd()\n",
    "path.append(f\"{cwd}/..\")\n",
    "from database import initialize_db, drop_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from doi_component.outlierness_component import *\n",
    "\n",
    "outlierness = OutliernessComponent()\n",
    "\n",
    "def doi(items: np.ndarray):\n",
    "  result = outlierness.compute_doi(items)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from database import get_next_chunk_from_db\n",
    "from storage_strategy.windowing_strategy import *\n",
    "from storage_strategy.compression_strategy import *\n",
    "from storage_strategy.reservoir_sampling_strategy import *\n",
    "\n",
    "drop_tables()\n",
    "initialize_db(\"../data/nyc_taxis.shuffled_full.csv.gz\")\n",
    "\n",
    "chunk_size = 1000\n",
    "chunks = 100\n",
    "max_storage_size = chunk_size * (2)\n",
    "\n",
    "start = time.time()\n",
    "windowing = WindowingStrategy(max_storage_size)\n",
    "t_window = time.time() - start\n",
    "start = time.time()\n",
    "compression = CompressionStrategy(max_storage_size)\n",
    "t_compression = time.time() - start\n",
    "start = time.time()\n",
    "reservoir = ReservoirSamplingStrategy(max_storage_size)\n",
    "t_reservoir = time.time() - start\n",
    "\n",
    "for i in range(chunks):\n",
    "  # chunk = pd.DataFrame(np.arange(i*chunk_size, (i+1)*chunk_size))\n",
    "  chunk = pd.DataFrame(get_next_chunk_from_db(chunk_size)).loc[:, [18, 19]]\n",
    "  \n",
    "  windowing.insert_chunk(chunk)\n",
    "  reservoir.insert_chunk(chunk)\n",
    "  compression.insert_chunk(chunk)\n",
    "\n",
    "print(\"types:\", windowing.get_storage().dtypes)\n",
    "\n",
    "print(\"timings:\")\n",
    "print(\"windowing\", t_window)\n",
    "print(\"compression\", t_compression)\n",
    "print(\"reservoir\", t_reservoir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowing.get_storage().plot.scatter(x=18, y=19, alpha=0.1)\n",
    "reservoir.get_storage().plot.scatter(x=18, y=19, alpha=0.1)\n",
    "compression.get_storage().plot.scatter(x=0, y=1, alpha=0.1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
