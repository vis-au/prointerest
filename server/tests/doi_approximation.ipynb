{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Progressively Approximating a DOI function \r\n",
    "The idea here is that in some cases, computing a doi function simply takes too long. \r\n",
    "Instead, we therefore train a regression model on a subset of the data and then progressively retrain it on a progressively maintained sample of the data (see ```progressive_sampling.ipynb```)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import time\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import precision_score, jaccard_score, f1_score\r\n",
    "from sklearn.datasets import make_blobs\r\n",
    "from imblearn.under_sampling import RandomUnderSampler\r\n",
    "\r\n",
    "# outlier models used for doi computation\r\n",
    "# from sklearn.svm import OneClassSVM\r\n",
    "# from sklearn.neighbors import LocalOutlierFactor\r\n",
    "# from sklearn.covariance import EllipticEnvelope\r\n",
    "from sklearn.ensemble import IsolationForest\r\n",
    "\r\n",
    "\r\n",
    "# approximation models used for testing\r\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\r\n",
    "from sklearn.naive_bayes import BernoulliNB\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\r\n",
    "\r\n",
    "\r\n",
    "# use outlierness computation as doi function for now\r\n",
    "contamination = 0.01\r\n",
    "# doi = EllipticEnvelope(contamination=contamination, random_state=0)\r\n",
    "# doi = OneClassSVM(nu=contamination, kernel=\"rbf\", gamma=0.1)\r\n",
    "# doi = LocalOutlierFactor(n_neighbors=35, contamination=contamination)\r\n",
    "doi = IsolationForest(contamination=contamination, random_state=0)\r\n",
    "\r\n",
    "# generate data\r\n",
    "N = 1000000\r\n",
    "training_size = 1000\r\n",
    "features = 2\r\n",
    "chunk_size = 1000\r\n",
    "\r\n",
    "blobs_params = dict(n_samples=N, n_features=features)\r\n",
    "X = make_blobs(centers=6, cluster_std=1, **blobs_params)[0]\r\n",
    "\r\n",
    "# compute the \"ground truth\" by evaluating the doi function over the entire dataset (only useful in \r\n",
    "# benchmarking, since not feasible in PVA!)\r\n",
    "y = doi.fit_predict(X)\r\n",
    "\r\n",
    "# since the doi classes (for outlierness) are highly imbalanced (contamination variable indicates \r\n",
    "# the percentage that is considered outlier), we balance the classes before evaluation.\r\n",
    "rus = RandomUnderSampler(random_state=0)\r\n",
    "X_res, y_res = rus.fit_resample(X, y)\r\n",
    "idx = np.random.permutation(len(X_res))\r\n",
    "X_res, y_res = X_res[idx], y_res[idx]\r\n",
    "\r\n",
    "steps = (len(X_res) // chunk_size) + 1\r\n",
    "\r\n",
    "models = [\r\n",
    "  [\"bernoulli nb\", BernoulliNB(alpha=0.5, binarize=0.0, class_prior=None, fit_prior=True)],\r\n",
    "  [\"passive-aggressive\", PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)],\r\n",
    "  [\"decision tree\", DecisionTreeClassifier(random_state=0)],\r\n",
    "  [\"random forest\", RandomForestClassifier(random_state=0)],\r\n",
    "  [\"gradient boosting\", GradientBoostingClassifier(random_state=0)],\r\n",
    "]\r\n",
    "\r\n",
    "# containers for benchmarking variables\r\n",
    "TIMES = []\r\n",
    "F_SCORE = []\r\n",
    "J_SCORE = []\r\n",
    "\r\n",
    "for title, model in models:\r\n",
    "  prediction = np.array([])\r\n",
    "\r\n",
    "  # scores\r\n",
    "  precision = np.array([])\r\n",
    "  f1 = np.array([])\r\n",
    "  jaccard = np.array([])\r\n",
    "\r\n",
    "  start = time.time()\r\n",
    "  for i in range(steps):\r\n",
    "    X_ = X_res[i * chunk_size: (i+1) * chunk_size]\r\n",
    "    y_ = y_res[i * chunk_size: (i+1) * chunk_size]\r\n",
    "\r\n",
    "    # on the first chunk, train the doi predictor by evaluating the doi function over the current\r\n",
    "    # chunk of data\r\n",
    "    if i == 0:\r\n",
    "      X_train = X[:training_size]\r\n",
    "      y_approx = doi.fit_predict(X_train)\r\n",
    "      model.fit(X_train, y_approx)\r\n",
    "\r\n",
    "    y_pred = model.predict(X_)\r\n",
    "    prediction = np.append(prediction, y_pred)\r\n",
    "\r\n",
    "    # score the prediction against the ground truth\r\n",
    "    p = precision_score(y_, y_pred)\r\n",
    "    f = f1_score(y_, y_pred)\r\n",
    "    j = jaccard_score(y_, y_pred)\r\n",
    "\r\n",
    "    # save the scores\r\n",
    "    precision = np.append(precision, p)\r\n",
    "    f1 = np.append(f1, f)\r\n",
    "    jaccard = np.append(jaccard, j)\r\n",
    "\r\n",
    "  end = time.time()\r\n",
    "  print(f\"{title}: {end-start}s\")\r\n",
    "\r\n",
    "  TIMES = TIMES + [end-start]\r\n",
    "  F_SCORE = F_SCORE + [f1]\r\n",
    "  J_SCORE = J_SCORE + [jaccard]\r\n",
    "\r\n",
    "  # create side-by-side visualization of prediction and ground_truth\r\n",
    "  fig, (ax1) = plt.subplots(1, 2, figsize=(15, 5))\r\n",
    "  fig.suptitle(title)\r\n",
    "\r\n",
    "  alpha = 0.05\r\n",
    "  ax1[0].set_title(\"Prediction\")\r\n",
    "  ax1[0].scatter(x=X_res[prediction == -1,0], y=X_res[prediction == -1,1], c=prediction[prediction == -1], alpha=alpha)\r\n",
    "  ax1[1].set_title(\"Ground truth\")\r\n",
    "  ax1[1].scatter(x=X_res[y_res == -1,0], y=X_res[y_res == -1,1], c=y_res[y_res == -1], alpha=alpha)\r\n",
    "  plt.show()\r\n",
    "\r\n",
    "TIMES = np.array(TIMES)\r\n",
    "F_SCORE = np.array(F_SCORE)\r\n",
    "J_SCORE = np.array(J_SCORE)\r\n",
    "\r\n",
    "# visualize the benchmarks\r\n",
    "columns = np.array(models)[:, 0]\r\n",
    "fig, (ax) = plt.subplots(1, 3, figsize=(15, 5))\r\n",
    "fig.suptitle(\"scores\")\r\n",
    "ax[0].set_title(\"runtime\")\r\n",
    "ax[0].bar(columns, TIMES)\r\n",
    "ax[1].set_title(\"f1\")\r\n",
    "ax[1].boxplot(F_SCORE.transpose(), labels=columns)\r\n",
    "ax[1].set_ylim([0, 1])\r\n",
    "ax[2].set_title(\"jaccard\")\r\n",
    "ax[2].boxplot(J_SCORE.transpose(), labels=columns)\r\n",
    "ax[2].set_ylim([0, 1])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}